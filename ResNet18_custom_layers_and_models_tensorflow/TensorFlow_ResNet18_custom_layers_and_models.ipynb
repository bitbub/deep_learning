{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "q4ZhggR0gWPl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc1e3d9f-f28b-4670-baab-5c9bcfd70481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Custom Lambda Layers in TensorFlow\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "    ## here instead of using 'relu', we provied customized lambda layer.\n",
        "    tf.keras.layers.Dense(units=128),\n",
        "    tf.keras.layers.Lambda(lambda x: tf.abs(x)),\n",
        "    tf.keras.layers.Dense(units=10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "hyH9SlFA6k1k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Custom function for lambda layers.\n",
        "\n",
        "## Let's give customize the relu in a function, and pass it in lambda layer.\n",
        "\n",
        "def my_relu(x):\n",
        "  return K.maximum(0.5, x)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "    ## here instead of using 'relu', we provied customized lambda layer.\n",
        "    tf.keras.layers.Dense(units=128),\n",
        "    tf.keras.layers.Lambda(my_relu),\n",
        "    tf.keras.layers.Dense(units=10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "9bO8MVRn6kx9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Implementing custom layers."
      ],
      "metadata": {
        "id": "5TYCRjdpXlx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Implementing custom layers.\n",
        "### A layer in tensorflow is a class that collects parameters to encapsulate state(weights) and computation(forward pass). Here weights can be trainable or set to be un-trainable.\n",
        "\n",
        "\n",
        "class SimpleDense(Layer): ## inherit tensorflow's Layer class.\n",
        "\n",
        "  def __init__(self, units=32, activation=None):\n",
        "    super(SimpleDense, self).__init__()\n",
        "    self.units = units\n",
        "    self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "  def build(self, input_shape): # create/initialize a state of the layer(defining weights, kernel(w) and bias(b))\n",
        "\n",
        "    w_init = tf.random_normal_initializer()\n",
        "\n",
        "    self.w = tf.Variable(name = 'kernel',\n",
        "                         initial_value = w_init(shape=(input_shape[-1], self.units),\n",
        "                                                dtype='float32'\n",
        "                                                ),\n",
        "                         trainable=True\n",
        "                         )\n",
        "\n",
        "\n",
        "    b_init = tf.zeros_initializer()\n",
        "\n",
        "    self.b = tf.Variable(name = 'bias',\n",
        "                         initial_value=b_init(shape=(self.units,),\n",
        "                                              dtype='float32'\n",
        "                                              ),\n",
        "                         trainable=True\n",
        "                         )\n",
        "\n",
        "  def call(self, inputs): ## defines the computation in the layers from inputs to outputs\n",
        "    return self.activation( tf.matmul(inputs, self.w) + self.b )\n",
        "\n"
      ],
      "metadata": {
        "id": "7NSALUTk6kvF"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_dense = SimpleDense(units=1)\n",
        "x = tf.ones((1,1))\n",
        "print(x)\n",
        "y = my_dense(x)\n",
        "\n",
        "print(my_dense.variables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sar6zM6_6ksM",
        "outputId": "909fd9b4-f345-4ca4-b669-8e53b296c7b8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
            "[<tf.Variable 'simple_dense_33/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[0.02248342]], dtype=float32)>, <tf.Variable 'simple_dense_33/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Training a neural network with your custom Layes.\n",
        "\n",
        "xs = np.reshape(np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float), newshape=(6,1))\n",
        "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\n",
        "\n",
        "\n",
        "\n",
        "my_layer = SimpleDense(units=1)\n",
        "\n",
        "model = tf.keras.Sequential([my_layer])\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
        "\n",
        "model.fit(xs, ys, epochs=500, verbose=0)\n",
        "\n",
        "model.predict([10.0])\n",
        "\n",
        "print(my_layer.weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjEm1tS76kp1",
        "outputId": "8f3b312c-a4dc-4fd5-c060-2f499f31c5da"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 54ms/step\n",
            "[<tf.Variable 'simple_dense_41/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[1.9972883]], dtype=float32)>, <tf.Variable 'simple_dense_41/bias:0' shape=(1,) dtype=float32, numpy=array([-0.99159294], dtype=float32)>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CDrr6Kb86kkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Complex Architectures with the Functional API - Custom Models"
      ],
      "metadata": {
        "id": "asrLWwmSXYsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Custom Models\n",
        "\n",
        "class WideAndDeepModel(Model):\n",
        "\n",
        "  def __init__(self, units=30, activation='relu', **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.hidden_1 = tf.keras.layers.Dense(units = units, activation = activation)\n",
        "    self.hidden_2 = tf.keras.layers.Dense(units = units, activation = activation)\n",
        "    self.main_output = tf.keras.layers.Dense(units = 1)\n",
        "    self.aux_output = tf.keras.layers.Dense(units = 1)\n",
        "\n",
        "\n",
        "  def call(self, inputs):\n",
        "\n",
        "    input_a, input_b = inputs\n",
        "\n",
        "    hidden_1 = self.hidden_1(input_b)\n",
        "    hidden_2 = self.hidden_2(hidden_1)\n",
        "    concat = tf.keras.layers.concatenate([input_a, hidden_2])\n",
        "    main_output = self.main_output(concat)\n",
        "    aux_output = self.aux_output(hidden_2)\n",
        "\n",
        "    return main_output, aux_output\n"
      ],
      "metadata": {
        "id": "_5PSm_9KXWTq"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = WideAndDeepModel()"
      ],
      "metadata": {
        "id": "8SuXvNAPXWQ8"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Model class to simplify complex architectures - Residual Networks (ResNets)"
      ],
      "metadata": {
        "id": "uqUu-C1JiNFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## convolutional layers block\n",
        "class CNNResidual(Layer):\n",
        "\n",
        "  def __init__(self, layers, filters, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.hidden = [ tf.keras.layers.Conv2D(filters, kernel_size=(3,3), activation='relu')\n",
        "                  for _ in range(layers) ]\n",
        "\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = inputs\n",
        "    for layer in self.hidden:\n",
        "      x = layer(x)\n",
        "      return inputs + x\n",
        "\n",
        "## Dense layers block\n",
        "class DNNResidual(Layer):\n",
        "\n",
        "  def __init__(self, layers, neurons, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.hidden = [ tf.keras.layers.Dense(units = neurons, activation='relu')\n",
        "                  for _ in range(layers) ]\n",
        "\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = inputs\n",
        "    for layer in self.hidden:\n",
        "      x = layer(x)\n",
        "      return inputs + x\n",
        "\n",
        "## create residual network from convolutional and dense layer blocks.\n",
        "class MyResidual(Model):\n",
        "  def __init__(self, **kwargs):\n",
        "    self.hidden_1 = tf.keras.layers.Dense(units=30, activation='relu')\n",
        "    self.blocl_1 = CNNResidual(2, 32).   ## convolutional block\n",
        "    self.blocl_2 = DNNResidual(2, 64)    ## dense block\n",
        "    self.out = tf.keras.layers.Dense(units=1)\n",
        "\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.hidden_1(inputs)\n",
        "    x = self.blocl_1(x)\n",
        "\n",
        "    for _ in range(1, 4):\n",
        "      x = self.blocl_2(x)\n",
        "\n",
        "    return self.out(x)"
      ],
      "metadata": {
        "id": "cqgHAnr86kh0"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet-18 architechture"
      ],
      "metadata": {
        "id": "Wqd0M-ruoBBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## build indentity block\n",
        "\n",
        "class IdentityBlock(tf.keras.Model):\n",
        "  def __init__(self, filters, kernel_size):\n",
        "    super(IdentityBlock, self).__init__(name='')\n",
        "\n",
        "    self.conv1 = tf.keras.layers.Conv2D(filters, kernel_size, padding='same')\n",
        "    self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    self.conv2 = tf.keras.layers.Conv2D(filters, kernel_size, padding='same')\n",
        "    self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    self.act = tf.keras.layers.Activation('relu')\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, input_tensor):\n",
        "    x = self.conv1(input_tensor)\n",
        "    x = self.bn1(x)\n",
        "    x = self.act(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "\n",
        "    x = self.add([x, input_tensor])\n",
        "    x = self.act(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vg-xFfkA6ke5"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, num_classes): ## 'num_classes' for classifier layer\n",
        "    super(ResNet, self).__init__()\n",
        "\n",
        "    self.conv = tf.keras.layers.Conv2D(64, 7, padding='same')\n",
        "    self.bn = tf.keras.layers.BatchNormalization()\n",
        "    self.act = tf.keras.layers.Activation('relu')\n",
        "    self.max_pool = tf.keras.layers.MaxPool2D(pool_size=(3,3))\n",
        "\n",
        "    self.id1a = IdentityBlock(64, 3)\n",
        "    self.id1b = IdentityBlock(64, 3)\n",
        "\n",
        "    self.global_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "    self.classifier = tf.keras.layers.Dense(units = num_classes, activation='softmax')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.conv(inputs)\n",
        "    x = self.bn(x)\n",
        "    x = self.act(x)\n",
        "    x = self.max_pool(x)\n",
        "\n",
        "    x = self.id1a(x)\n",
        "    x = self.id1b(x)\n",
        "\n",
        "    x = self.global_pool(x)\n",
        "\n",
        "    return self.classifier(x)\n"
      ],
      "metadata": {
        "id": "C_qKUXEw6kW-"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess(features):\n",
        "  return tf.cast(features['image'], tf.float32) /255.0 , features['label']\n",
        "\n",
        "resnet = ResNet(10)\n",
        "resnet.compile(optimizer='adam',\n",
        "               loss='sparse_categorical_crossentropy',\n",
        "               metrics=['accuracy']\n",
        "               )\n",
        "\n",
        "dataset = tfds.load('mnist',  split='train')\n",
        "dataset = dataset.map(preprocess).batch(32)\n",
        "\n",
        "resnet.fit(dataset, epochs=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6zXgPZciWut",
        "outputId": "b2268368-ff31-4490-c6e4-8158540e42df"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 233s 123ms/step - loss: 0.1245 - accuracy: 0.9665\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ab0c015d690>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-8F7wpYNiWsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8zwzz_Z_6Cbe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}